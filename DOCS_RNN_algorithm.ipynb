{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from configs import TIMEZONE, LOG_FILE_NAME, set_logger\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from alpaca.trading.client import TradingClient\n",
    "from alpaca.trading.requests import MarketOrderRequest\n",
    "from alpaca.trading.enums import OrderSide, TimeInForce\n",
    "from alpaca.trading.requests import GetAssetsRequest\n",
    "from alpaca.data.historical import StockHistoricalDataClient, CryptoHistoricalDataClient\n",
    "from alpaca.data.requests import StockLatestQuoteRequest, StockBarsRequest, CryptoLatestQuoteRequest\n",
    "from alpaca.data.requests import CryptoBarsRequest\n",
    "from alpaca.trading.models import Order\n",
    "from alpaca.data.timeframe import TimeFrame\n",
    "from my_secrets import ALPACA_API_BASE_URL, PAPER_API_ID, PAPER_SECRET_KEY\n",
    "import logging\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "set_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Trade_Class import Stock_Trader, Crypto_Trader\n",
    "from Market_Monitor import Market_Monitor\n",
    "from ALGO_crossover import bars_df_filter_dates, add_sma_columns, add_sma_crossovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_trader = Stock_Trader(PAPER_API_ID, PAPER_SECRET_KEY, paper=True)\n",
    "monitor = Market_Monitor(stock_trader.trading_client, TIMEZONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1804, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-12-01 05:00:00+00:00</td>\n",
       "      <td>118.75</td>\n",
       "      <td>118.81</td>\n",
       "      <td>116.86</td>\n",
       "      <td>117.34</td>\n",
       "      <td>34852374.0</td>\n",
       "      <td>187129.0</td>\n",
       "      <td>117.756760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-12-02 05:00:00+00:00</td>\n",
       "      <td>117.05</td>\n",
       "      <td>118.11</td>\n",
       "      <td>116.08</td>\n",
       "      <td>116.28</td>\n",
       "      <td>33385643.0</td>\n",
       "      <td>180616.0</td>\n",
       "      <td>117.151198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-12-03 05:00:00+00:00</td>\n",
       "      <td>116.55</td>\n",
       "      <td>116.79</td>\n",
       "      <td>114.22</td>\n",
       "      <td>115.20</td>\n",
       "      <td>41560785.0</td>\n",
       "      <td>245330.0</td>\n",
       "      <td>115.434888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-12-04 05:00:00+00:00</td>\n",
       "      <td>115.29</td>\n",
       "      <td>119.25</td>\n",
       "      <td>115.11</td>\n",
       "      <td>119.03</td>\n",
       "      <td>57776977.0</td>\n",
       "      <td>307788.0</td>\n",
       "      <td>118.187290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-12-07 05:00:00+00:00</td>\n",
       "      <td>118.98</td>\n",
       "      <td>119.86</td>\n",
       "      <td>117.81</td>\n",
       "      <td>118.28</td>\n",
       "      <td>32080754.0</td>\n",
       "      <td>190809.0</td>\n",
       "      <td>118.509111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol                 timestamp    open    high     low   close  \\\n",
       "0   AAPL 2015-12-01 05:00:00+00:00  118.75  118.81  116.86  117.34   \n",
       "1   AAPL 2015-12-02 05:00:00+00:00  117.05  118.11  116.08  116.28   \n",
       "2   AAPL 2015-12-03 05:00:00+00:00  116.55  116.79  114.22  115.20   \n",
       "3   AAPL 2015-12-04 05:00:00+00:00  115.29  119.25  115.11  119.03   \n",
       "4   AAPL 2015-12-07 05:00:00+00:00  118.98  119.86  117.81  118.28   \n",
       "\n",
       "       volume  trade_count        vwap  \n",
       "0  34852374.0     187129.0  117.756760  \n",
       "1  33385643.0     180616.0  117.151198  \n",
       "2  41560785.0     245330.0  115.434888  \n",
       "3  57776977.0     307788.0  118.187290  \n",
       "4  32080754.0     190809.0  118.509111  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = datetime(year=2015, month=1, day=1, hour=0, minute=0, second=0)\n",
    "end = datetime(year=2023, month=2, day=1, hour=0, minute=0, second=0)\n",
    "bars_df = stock_trader.get_bars('AAPL', start=start, end=end, time_resolution='day')\n",
    "bars_df.reset_index(inplace=True)\n",
    "bars_df.sort_values(by=['timestamp'], ascending=True, inplace=True)\n",
    "print(bars_df.shape)\n",
    "display(bars_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_RNN_data(bars_df, col='close', test_pct=0.25, scaler=None):\n",
    "    array = bars_df[col].values\n",
    "    if scaler!=None:\n",
    "        array = scaler.fit_transform(array.reshape(-1, 1))\n",
    "    train_size = len(array) - int(len(array)*test_pct)\n",
    "    train_array = array[:train_size]\n",
    "    test_array = array[train_size:]\n",
    "    return train_array, test_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 50\n",
    "NUM_EXAMPLES = 949\n",
    "NUM_LAYERS = 2\n",
    "HIDDEN_SIZE = 256\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "TEST_PCT = 0.25\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1353, 451)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array, test_array = prep_RNN_data(bars_df, col='close', test_pct=TEST_PCT, scaler=MinMaxScaler())\n",
    "len(train_array), len(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, seq_len):\n",
    "        \"\"\"\n",
    "        Takes in `data` which is a numpy array and `seq_len` which is an int.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.seq_len = seq_len\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.data) - self.seq_len) - 1\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index : index+self.seq_len], self.data[index+self.seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1302, 400)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = RNNDataset(train_array, SEQUENCE_LENGTH)\n",
    "test_dataset = RNNDataset(test_array, SEQUENCE_LENGTH)\n",
    "\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, BATCH_SIZE, drop_last=True, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 1]), torch.Size([1]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = train_dataset[0]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.unsqueeze(0)\n",
    "x.shape #creating a \"batch\" of 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have `torch.Size([1, 50, 1])`. <br>We will set `batch_first=True` in the `nn.RNN` such that we have the data provided as (*batch*,*seq*,*feature*).<br>\n",
    "So in our case we have *batch* size 1, *seq* size 50, *feature* size 1. The `input_size` to the RNN should be the same as *feature* size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(input_size=1, hidden_size=200, num_layers=1, batch_first=True)\n",
    "fc = nn.Linear(200, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_out, hn = rnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 200])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 200])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_model(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, num_layers, batch_size, device):\n",
    "        super(LSTM_model, self).__init__()\n",
    "        self.in_size = in_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.lstm = nn.LSTM(input_size=self.in_size, hidden_size=self.hidden_size, num_layers=self.num_layers)\n",
    "        self.fc = nn.Linear(self.hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, hn, cn):\n",
    "        out, (hn, cn) = self.lstm(x, (hn, cn))\n",
    "        final_out = self.fc(out[-1])\n",
    "        return final_out, hn, cn\n",
    "    \n",
    "    def predict(self, x):\n",
    "        hn, cn = self.init()\n",
    "        final_out = self.fc(out[-1])\n",
    "        return final_out\n",
    "    \n",
    "    def init(self):\n",
    "        h0 = torch.zeros(self.num_layers, self.batch_size, self.hidden_size).to(self.device)\n",
    "        c0 = torch.zeros(self.num_layers, self.batch_size, self.hidden_size).to(self.device)\n",
    "        return h0.to(self.device), c0.to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, in_size, num_layers, hidden_size, device):\n",
    "        super(RNN, self).__init__()\n",
    "        self.in_size= in_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "\n",
    "        self.rnn = nn.RNN(input_size=self.in_size, hidden_size=self.hidden_size, num_layers=self.num_layers)\n",
    "        self.fc = nn.Linear(self.hidden_size*self.in_size, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #assert x.shape == (self.in_size,)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_model(\n",
       "  (lstm): LSTM(1, 256, num_layers=2)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM_model(1, HIDDEN_SIZE, NUM_LAYERS, BATCH_SIZE, DEVICE) #so I think 1 gets passed as the input size which would be like the number of features. \n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_fit(model, train_loader, optimizer, loss_fn):\n",
    "    hn, cn = model.init()\n",
    "    model.train()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        x, y = batch\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        out, hn, cn = model(x.reshape(SEQUENCE_LENGTH, BATCH_SIZE, 1), hn, cn)\n",
    "        loss = loss_fn(out.reshape(BATCH_SIZE), y)\n",
    "        hn = hn.detach()\n",
    "        cn = cn.detach()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i == len(train_loader)-1:\n",
    "            print(f\"Train Loss({i}): {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_test(model, test_loader, loss_fn):\n",
    "    hn, cn = model.init()\n",
    "    model.eval()\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        x, y = batch\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        out, hn, cn = model(x.reshape(SEQUENCE_LENGTH, BATCH_SIZE, 1), hn, cn)\n",
    "        loss = loss_fn(out.reshape(BATCH_SIZE), y)\n",
    "        if i == len(test_loader)-1:\n",
    "            print(f\"Test Loss({i}): {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mike's PC\\Desktop\\Masters_DU\\MSDS_capstone\\capenv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:101: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss(39): 0.1207\n",
      "Test Loss(11): 0.0212\n",
      "Epoch: 1\n",
      "Train Loss(39): 0.1570\n",
      "Test Loss(11): 0.0433\n",
      "Epoch: 2\n",
      "Train Loss(39): 0.1148\n",
      "Test Loss(11): 0.0910\n",
      "Epoch: 3\n",
      "Train Loss(39): 0.1298\n",
      "Test Loss(11): 0.0659\n",
      "Epoch: 4\n",
      "Train Loss(39): 0.1282\n",
      "Test Loss(11): 0.0349\n",
      "Epoch: 5\n",
      "Train Loss(39): 0.1307\n",
      "Test Loss(11): 0.1361\n",
      "Epoch: 6\n",
      "Train Loss(39): 0.2266\n",
      "Test Loss(11): 0.1831\n",
      "Epoch: 7\n",
      "Train Loss(39): 0.1514\n",
      "Test Loss(11): 0.0533\n",
      "Epoch: 8\n",
      "Train Loss(39): 0.1263\n",
      "Test Loss(11): 0.0522\n",
      "Epoch: 9\n",
      "Train Loss(39): 0.1461\n",
      "Test Loss(11): 0.0225\n",
      "Epoch: 10\n",
      "Train Loss(39): 0.2020\n",
      "Test Loss(11): 0.2466\n",
      "Epoch: 11\n",
      "Train Loss(39): 0.1940\n",
      "Test Loss(11): 0.0795\n",
      "Epoch: 12\n",
      "Train Loss(39): 0.1606\n",
      "Test Loss(11): 0.1267\n",
      "Epoch: 13\n",
      "Train Loss(39): 0.1962\n",
      "Test Loss(11): 0.0338\n",
      "Epoch: 14\n",
      "Train Loss(39): 0.2705\n",
      "Test Loss(11): 0.1215\n",
      "Epoch: 15\n",
      "Train Loss(39): 0.1646\n",
      "Test Loss(11): 0.0396\n",
      "Epoch: 16\n",
      "Train Loss(39): 0.1682\n",
      "Test Loss(11): 0.1207\n",
      "Epoch: 17\n",
      "Train Loss(39): 0.2259\n",
      "Test Loss(11): 0.1391\n",
      "Epoch: 18\n",
      "Train Loss(39): 0.1760\n",
      "Test Loss(11): 0.1237\n",
      "Epoch: 19\n",
      "Train Loss(39): 0.1178\n",
      "Test Loss(11): 0.0483\n",
      "Epoch: 20\n",
      "Train Loss(39): 0.1476\n",
      "Test Loss(11): 0.1422\n",
      "Epoch: 21\n",
      "Train Loss(39): 0.2348\n",
      "Test Loss(11): 0.0258\n",
      "Epoch: 22\n",
      "Train Loss(39): 0.1210\n",
      "Test Loss(11): 0.1238\n",
      "Epoch: 23\n",
      "Train Loss(39): 0.1619\n",
      "Test Loss(11): 0.0377\n",
      "Epoch: 24\n",
      "Train Loss(39): 0.1123\n",
      "Test Loss(11): 0.0408\n",
      "Epoch: 25\n",
      "Train Loss(39): 0.1708\n",
      "Test Loss(11): 0.0208\n",
      "Epoch: 26\n",
      "Train Loss(39): 0.2158\n",
      "Test Loss(11): 0.1980\n",
      "Epoch: 27\n",
      "Train Loss(39): 0.1814\n",
      "Test Loss(11): 0.2749\n",
      "Epoch: 28\n",
      "Train Loss(39): 0.1209\n",
      "Test Loss(11): 0.1171\n",
      "Epoch: 29\n",
      "Train Loss(39): 0.1044\n",
      "Test Loss(11): 0.0473\n",
      "Epoch: 30\n",
      "Train Loss(39): 0.1435\n",
      "Test Loss(11): 0.0270\n",
      "Epoch: 31\n",
      "Train Loss(39): 0.3002\n",
      "Test Loss(11): 0.1606\n",
      "Epoch: 32\n",
      "Train Loss(39): 0.2137\n",
      "Test Loss(11): 0.0442\n",
      "Epoch: 33\n",
      "Train Loss(39): 0.1437\n",
      "Test Loss(11): 0.0194\n",
      "Epoch: 34\n",
      "Train Loss(39): 0.0971\n",
      "Test Loss(11): 0.0239\n",
      "Epoch: 35\n",
      "Train Loss(39): 0.1824\n",
      "Test Loss(11): 0.0757\n",
      "Epoch: 36\n",
      "Train Loss(39): 0.1338\n",
      "Test Loss(11): 0.1603\n",
      "Epoch: 37\n",
      "Train Loss(39): 0.1642\n",
      "Test Loss(11): 0.2129\n",
      "Epoch: 38\n",
      "Train Loss(39): 0.1622\n",
      "Test Loss(11): 0.1663\n",
      "Epoch: 39\n",
      "Train Loss(39): 0.1330\n",
      "Test Loss(11): 0.1243\n",
      "Epoch: 40\n",
      "Train Loss(39): 0.1289\n",
      "Test Loss(11): 0.0681\n",
      "Epoch: 41\n",
      "Train Loss(39): 0.1409\n",
      "Test Loss(11): 0.2260\n",
      "Epoch: 42\n",
      "Train Loss(39): 0.0915\n",
      "Test Loss(11): 0.0254\n",
      "Epoch: 43\n",
      "Train Loss(39): 0.0854\n",
      "Test Loss(11): 0.1120\n",
      "Epoch: 44\n",
      "Train Loss(39): 0.1816\n",
      "Test Loss(11): 0.0798\n",
      "Epoch: 45\n",
      "Train Loss(39): 0.1076\n",
      "Test Loss(11): 0.0189\n",
      "Epoch: 46\n",
      "Train Loss(39): 0.1894\n",
      "Test Loss(11): 0.2123\n",
      "Epoch: 47\n",
      "Train Loss(39): 0.1562\n",
      "Test Loss(11): 0.2093\n",
      "Epoch: 48\n",
      "Train Loss(39): 0.2348\n",
      "Test Loss(11): 0.0180\n",
      "Epoch: 49\n",
      "Train Loss(39): 0.1486\n",
      "Test Loss(11): 0.0683\n",
      "Epoch: 50\n",
      "Train Loss(39): 0.1167\n",
      "Test Loss(11): 0.1324\n",
      "Epoch: 51\n",
      "Train Loss(39): 0.2128\n",
      "Test Loss(11): 0.1579\n",
      "Epoch: 52\n",
      "Train Loss(39): 0.2174\n",
      "Test Loss(11): 0.1189\n",
      "Epoch: 53\n",
      "Train Loss(39): 0.1803\n",
      "Test Loss(11): 0.0235\n",
      "Epoch: 54\n",
      "Train Loss(39): 0.1415\n",
      "Test Loss(11): 0.1024\n",
      "Epoch: 55\n",
      "Train Loss(39): 0.1610\n",
      "Test Loss(11): 0.0516\n",
      "Epoch: 56\n",
      "Train Loss(39): 0.1395\n",
      "Test Loss(11): 0.0562\n",
      "Epoch: 57\n",
      "Train Loss(39): 0.1988\n",
      "Test Loss(11): 0.1059\n",
      "Epoch: 58\n",
      "Train Loss(39): 0.2222\n",
      "Test Loss(11): 0.0787\n",
      "Epoch: 59\n",
      "Train Loss(39): 0.1845\n",
      "Test Loss(11): 0.0788\n",
      "Epoch: 60\n",
      "Train Loss(39): 0.1387\n",
      "Test Loss(11): 0.1410\n",
      "Epoch: 61\n",
      "Train Loss(39): 0.1297\n",
      "Test Loss(11): 0.0617\n",
      "Epoch: 62\n",
      "Train Loss(39): 0.0889\n",
      "Test Loss(11): 0.1250\n",
      "Epoch: 63\n",
      "Train Loss(39): 0.1446\n",
      "Test Loss(11): 0.0178\n",
      "Epoch: 64\n",
      "Train Loss(39): 0.0915\n",
      "Test Loss(11): 0.0272\n",
      "Epoch: 65\n",
      "Train Loss(39): 0.1241\n",
      "Test Loss(11): 0.0510\n",
      "Epoch: 66\n",
      "Train Loss(39): 0.1342\n",
      "Test Loss(11): 0.1492\n",
      "Epoch: 67\n",
      "Train Loss(39): 0.2136\n",
      "Test Loss(11): 0.2574\n",
      "Epoch: 68\n",
      "Train Loss(39): 0.1475\n",
      "Test Loss(11): 0.2944\n",
      "Epoch: 69\n",
      "Train Loss(39): 0.0959\n",
      "Test Loss(11): 0.0177\n",
      "Epoch: 70\n",
      "Train Loss(39): 0.1258\n",
      "Test Loss(11): 0.0184\n",
      "Epoch: 71\n",
      "Train Loss(39): 0.2146\n",
      "Test Loss(11): 0.0537\n",
      "Epoch: 72\n",
      "Train Loss(39): 0.1529\n",
      "Test Loss(11): 0.2840\n",
      "Epoch: 73\n",
      "Train Loss(39): 0.1095\n",
      "Test Loss(11): 0.0972\n",
      "Epoch: 74\n",
      "Train Loss(39): 0.2086\n",
      "Test Loss(11): 0.1477\n",
      "Epoch: 75\n",
      "Train Loss(39): 0.1564\n",
      "Test Loss(11): 0.2134\n",
      "Epoch: 76\n",
      "Train Loss(39): 0.1451\n",
      "Test Loss(11): 0.1155\n",
      "Epoch: 77\n",
      "Train Loss(39): 0.1432\n",
      "Test Loss(11): 0.1186\n",
      "Epoch: 78\n",
      "Train Loss(39): 0.1628\n",
      "Test Loss(11): 0.0536\n",
      "Epoch: 79\n",
      "Train Loss(39): 0.1387\n",
      "Test Loss(11): 0.0442\n",
      "Epoch: 80\n",
      "Train Loss(39): 0.2241\n",
      "Test Loss(11): 0.2138\n",
      "Epoch: 81\n",
      "Train Loss(39): 0.1425\n",
      "Test Loss(11): 0.0373\n",
      "Epoch: 82\n",
      "Train Loss(39): 0.1437\n",
      "Test Loss(11): 0.2745\n",
      "Epoch: 83\n",
      "Train Loss(39): 0.2342\n",
      "Test Loss(11): 0.0901\n",
      "Epoch: 84\n",
      "Train Loss(39): 0.1232\n",
      "Test Loss(11): 0.0349\n",
      "Epoch: 85\n",
      "Train Loss(39): 0.1027\n",
      "Test Loss(11): 0.0198\n",
      "Epoch: 86\n",
      "Train Loss(39): 0.2302\n",
      "Test Loss(11): 0.0549\n",
      "Epoch: 87\n",
      "Train Loss(39): 0.1639\n",
      "Test Loss(11): 0.0330\n",
      "Epoch: 88\n",
      "Train Loss(39): 0.2337\n",
      "Test Loss(11): 0.1942\n",
      "Epoch: 89\n",
      "Train Loss(39): 0.1545\n",
      "Test Loss(11): 0.0386\n",
      "Epoch: 90\n",
      "Train Loss(39): 0.2406\n",
      "Test Loss(11): 0.1733\n",
      "Epoch: 91\n",
      "Train Loss(39): 0.1440\n",
      "Test Loss(11): 0.0352\n",
      "Epoch: 92\n",
      "Train Loss(39): 0.1325\n",
      "Test Loss(11): 0.2175\n",
      "Epoch: 93\n",
      "Train Loss(39): 0.1248\n",
      "Test Loss(11): 0.0957\n",
      "Epoch: 94\n",
      "Train Loss(39): 0.1985\n",
      "Test Loss(11): 0.1671\n",
      "Epoch: 95\n",
      "Train Loss(39): 0.1878\n",
      "Test Loss(11): 0.0620\n",
      "Epoch: 96\n",
      "Train Loss(39): 0.1771\n",
      "Test Loss(11): 0.0179\n",
      "Epoch: 97\n",
      "Train Loss(39): 0.1251\n",
      "Test Loss(11): 0.0658\n",
      "Epoch: 98\n",
      "Train Loss(39): 0.2111\n",
      "Test Loss(11): 0.0884\n",
      "Epoch: 99\n",
      "Train Loss(39): 0.1468\n",
      "Test Loss(11): 0.0920\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    pytorch_fit(model, train_loader, optimizer, loss_fn)\n",
    "    pytorch_test(model, test_loader, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "462b05c1d6884d74e4190996522791c5c80e16a9d739d4e011be9ff74c38056f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
